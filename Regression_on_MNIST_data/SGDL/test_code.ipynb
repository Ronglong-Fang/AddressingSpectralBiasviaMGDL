{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537e0995-922a-4a54-a21c-0ce4f6b4387c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfcf681-be69-4e0c-87ca-7eb9eed8cffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 14:43:41.424888: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/SGDL/main_run.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_learning_rate \u001b[38;5;129;01min\u001b[39;00m MAX_learning_rate:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m min_learning_rate \u001b[38;5;129;01min\u001b[39;00m MIN_learning_rate:        \n\u001b[0;32m---> 19\u001b[0m         \u001b[43msingle_dnn_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_learning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_learning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/SGDL/singlegrade_dnn_main.py:53\u001b[0m, in \u001b[0;36msingle_dnn_main\u001b[0;34m(layers_dims, max_learning_rate, min_learning_rate, epochs, mini_batch_size, SGD, freq, amp)\u001b[0m\n\u001b[1;32m     50\u001b[0m opt\u001b[38;5;241m.\u001b[39mAMP_Z \u001b[38;5;241m=\u001b[39m amp              \u001b[38;5;66;03m# <--- Amplitude of noise\u001b[39;00m\n\u001b[1;32m     51\u001b[0m data  \u001b[38;5;241m=\u001b[39m get_mnist(opt)\n\u001b[0;32m---> 53\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msinglegrade_dnn_model_grade\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_parameter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m opt\n\u001b[1;32m     56\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/SGDL/singlegrade_dnn_regression.py:670\u001b[0m, in \u001b[0;36msinglegrade_dnn_model_grade\u001b[0;34m(data, nn_parameter, opt_parameter)\u001b[0m\n\u001b[1;32m    667\u001b[0m N, caches \u001b[38;5;241m=\u001b[39m singlegrade_model_forward(minibatch_X, layers_dims, parameters, activation, sinORrelu)\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43msinglegrade_backward_L2reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminibatch_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambd_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msinORrelu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m t \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Adam counter\u001b[39;00m\n\u001b[1;32m    672\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m max_learning_rate \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mexp( gamma \u001b[38;5;241m*\u001b[39m i )    \n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/SGDL/singlegrade_dnn_regression.py:342\u001b[0m, in \u001b[0;36msinglegrade_backward_L2reg\u001b[0;34m(Y, N, layers_dims, parameters, caches, lambd_W, activation, sinORrelu)\u001b[0m\n\u001b[1;32m    339\u001b[0m         grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)] \u001b[38;5;241m=\u001b[39m singlegrade_linear_activation_backward_L2reg(grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)], caches[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m    340\u001b[0m                                                                                                                          lambd_W, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 342\u001b[0m         grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)] \u001b[38;5;241m=\u001b[39m \u001b[43msinglegrade_linear_activation_backward_L2reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m                                                                                                                         \u001b[49m\u001b[43mlambd_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m           \n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/SGDL/singlegrade_dnn_regression.py:278\u001b[0m, in \u001b[0;36msinglegrade_linear_activation_backward_L2reg\u001b[0;34m(dN, cache, lambd_W, activation)\u001b[0m\n\u001b[1;32m    276\u001b[0m dW \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(dZ, N_prev\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m lambd_W\u001b[38;5;241m*\u001b[39mW             \n\u001b[1;32m    277\u001b[0m db \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dZ, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 278\u001b[0m dN_prev \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dN_prev, dW, db\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run main_run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3f0cf-6b86-4265-92bd-0b686fe7bedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
