{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649d88de-e5bf-4268-be9e-bffcb800c3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60dc093a-b386-423b-acbc-ba62cf8fe356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 14:23:11.328468: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------grade : 1---------------------\n",
      "\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "\n",
      "----------------------grade : 2---------------------\n",
      "\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "\n",
      "----------------------grade : 3---------------------\n",
      "\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "\n",
      "----------------------grade : 1---------------------\n",
      "\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n",
      "------------------we use xavier initialize-------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/MGDL/main_run.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_learning_rate \u001b[38;5;129;01min\u001b[39;00m MAX_learning_rate:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m min_learning_rate \u001b[38;5;129;01min\u001b[39;00m MIN_learning_rate:\n\u001b[0;32m---> 19\u001b[0m         \u001b[43mmulti_grade_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_learning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_learning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmul_layers_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmul_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/MGDL/multigrade_dnn_main.py:70\u001b[0m, in \u001b[0;36mmulti_grade_dnn\u001b[0;34m(max_learning_rate, min_learning_rate, mul_layers_dims, mul_epochs, SGD, mini_batch, freq, amp)\u001b[0m\n\u001b[1;32m     68\u001b[0m data  \u001b[38;5;241m=\u001b[39m get_mnist(opt)\n\u001b[1;32m     69\u001b[0m trained_variable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m opt\n\u001b[0;32m---> 70\u001b[0m trained_variable \u001b[38;5;241m=\u001b[39m \u001b[43mm_dnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultigrade_dnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrained_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     75\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMGDL_batchzie\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_epochs\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_MAXLrate\u001b[39m\u001b[38;5;132;01m%.2e\u001b[39;00m\u001b[38;5;124m_MINLrate\u001b[39m\u001b[38;5;132;01m%.2e\u001b[39;00m\u001b[38;5;124m_vLoss\u001b[39m\u001b[38;5;132;01m%.4e\u001b[39;00m\u001b[38;5;124m_cleanvloss\u001b[39m\u001b[38;5;132;01m%.4e\u001b[39;00m\u001b[38;5;124m_tLoss\u001b[39m\u001b[38;5;132;01m%.4e\u001b[39;00m\u001b[38;5;124m_amp\u001b[39m\u001b[38;5;132;01m%.1e\u001b[39;00m\u001b[38;5;124m_freq\u001b[39m\u001b[38;5;132;01m%.1e\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(opt_parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmini_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],opt_parameter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     76\u001b[0m                                                                                                                             opt_parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_learning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     77\u001b[0m                                                                                                                             opt_parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_learning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m                                                                                                                             trained_variable[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_costs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m     81\u001b[0m                                                                                                                             opt\u001b[38;5;241m.\u001b[39mAMP_Z, opt\u001b[38;5;241m.\u001b[39mNORM_K)\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/MGDL/multigrade_dnn_model.py:56\u001b[0m, in \u001b[0;36mmultigrade_dnn_model\u001b[0;34m(nn_parameter, opt_parameter, trained_variable, data)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     55\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 56\u001b[0m     trained_variable, prev_info \u001b[38;5;241m=\u001b[39m \u001b[43mm_dnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultigrade_dnn_model_grade_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambd_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_learning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_learning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:           \n\u001b[1;32m     58\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/MGDL/multigrade_dnn_regression.py:647\u001b[0m, in \u001b[0;36mmultigrade_dnn_model_grade_1\u001b[0;34m(trained_variable, data, layers_dims, lambd_W, opt_parameter, max_learning_rate, min_learning_rate, epochs, activation)\u001b[0m\n\u001b[1;32m    643\u001b[0m N, caches \u001b[38;5;241m=\u001b[39m multigrade_model_forward(minibatch_X, layers_dims, parameters, activation)\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mmultigrade_backward_L2reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminibatch_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambd_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# gradient checking\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m#gradient_check_n(layers_dims, parameters,  grads, minibatch_X, minibatch_Y, lambd_W, activation, epsilon=1e-7)\u001b[39;00m\n\u001b[1;32m    654\u001b[0m t \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Adam counter\u001b[39;00m\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/MGDL/multigrade_dnn_regression.py:332\u001b[0m, in \u001b[0;36mmultigrade_backward_L2reg\u001b[0;34m(Y, N, layers_dims, parameters, caches, lambd_W, activation)\u001b[0m\n\u001b[1;32m    329\u001b[0m         grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)] \u001b[38;5;241m=\u001b[39m multigrade_linear_activation_backward_L2reg(grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)], caches[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m    330\u001b[0m                                                                                                                          lambd_W, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m         grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdW\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)], grads[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)] \u001b[38;5;241m=\u001b[39m \u001b[43mmultigrade_linear_activation_backward_L2reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaches\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m                                                                                                                         \u001b[49m\u001b[43mlambd_W\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m           \n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads\n",
      "File \u001b[0;32m~/Multiscale_Multigrade_deep_nueral_network/Exponent_decay_learning_rate/Addressing_Spectral_Bias_Final_Code/Regression_on_MNIST_data/MGDL/multigrade_dnn_regression.py:274\u001b[0m, in \u001b[0;36mmultigrade_linear_activation_backward_L2reg\u001b[0;34m(dN, cache, lambd_W, activation)\u001b[0m\n\u001b[1;32m    272\u001b[0m dW \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(dZ, N_prev\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m lambd_W\u001b[38;5;241m*\u001b[39mW             \n\u001b[1;32m    273\u001b[0m db \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dZ, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 274\u001b[0m dN_prev \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dN_prev, dW, db\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run main_run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae17756-149a-4be9-998b-734c9bae5153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
